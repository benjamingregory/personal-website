## One Big Takeaway from GDC 2025

Last modified: 2025-03-25

---

Last week, I decided to attend GDC 2025 in San Francisco.
I worked at Activision during business school, and while I no longer work
directly in the industry, I still follow game development closely—especially
where AI intersects with tedious workflows that could be automated.
There's an understandable tension between creative tools and automation,
which can cause the gaming industry to ironically be late adopters to new tech.
But there's also a massive problem with crunch (i.e. unpaid overtime)
to get games out the door (there's even a Wikipedia article about it
-- https://en.wikipedia.org/wiki/Crunch_(video_games)) so there has to be a solution.

I impulsively bought an Expo pass, unsure if it would be worth it but hopeful
there'd be some companies working on incorporating AI in interesting ways.
As it turns out, it absolutely was. Several companies are leveraging AI in
game development in exciting ways but there’s one I really wanted to highlight.

<br />
### Coplay: The Cursor for Game Development

Coplay has developed a chat interface plugin for game engines (currently supporting Unity,
with plans to expand to other platforms). At GDC, [Jos van der Westhuizen](https://www.linkedin.com/in/josvdw/),
co-founder and CEO, demonstrated how Coplay can make game edits and create entire new
levels from scratch, complete with physics and combat mechanics.

Rather than try to explain it myself, I'll let them do it:

<br />
[![alt text](https://img.youtube.com/vi/ipcNw4CVGiM/0.jpg)](https://www.youtube.com/watch?v=ipcNw4CVGiM)
<br />
After their presentation, I had the opportunity to discuss the product's future with
[Joned Sarwar](https://www.linkedin.com/in/joned-sarwar-59055827/), co-founder and
CTO. Our conversation sparked some interesting ideas about where this technology
could evolve.

_Note: The following represents my own vision for the technology's potential, not
necessarily Coplay's roadmap._

<br />
### Level 1 – Vibe Game Development

The “vibe” moniker is a little overhyped right
now and people kind of have a kneejerk reaction to it as either a revolutionary
accelerant or a tech debt nightmare waiting to happen. I think the truth is in
the middle and for early learning and rapid prototyping, the ability to stay in
the flow and tweak things you know you want but aren’t familiar with which setting
to manipulate, I do have to say it’s game changing and Jos showed a great demo
where he showed this in practice.

<br />
Creating menus, tweaking settings, adding scripting logic for character interactions;
all of this stuff is trivial to do with Coplay. This is the most immediate use case
for Coplay and I think it’s going to be a hit with both new developers who have a
fuzzy vision of what they want but don't necessarily know how to get there and experienced
developers who know exactly what they want and don’t want to spend time clicking
through menus to get there.

<br />
### Level 2 - Agentic Game Development

From their experience building games, the team at Coplay clearly knows that devs
have workflows that are specific to their project and style. That's why there's a
recording button where you can have Coplay watch what you're doing and record the actions
to learn what is happening and what is trying to be accomplished. Walking the model
through each step of the process is exactly what you would do with a new member of
your team and will help the AI avoid the pitfalls of not understanding the context
of what you're asking or hallucinate and create something totally from far afield.
This is where I think Coplay could really shine. Imagine a world where you have
a team of agents who are trained on accomplishing specific tasks.

<br />
Agents could specialize in scene development (e.g. Create a shader for a rainy day
scene with reflective puddles and dark clouds), asset creation (e.g. Generate a dense,
overgrown forest with varied terrain, ancient ruins, and soft, diffused lighting.),
or even NPC mechanics (e.g.Generate an AI script for an enemy that patrols an area,
chases the player on sight, and retreats when health is low.) What’s more, agents
could leverage MCPs to plug into other generative platforms -- something Coplay can
already do with integrations into Meshy and Tripo for asset creation. Once AIs are
intialized with proper context, they could work together to take the seed of a game
that is tightly tuned and build out new levels, variations on existing levels, or
even entirely new games in the same style.
<br />
### Level 3 -- Abstracted Game Development

Watching Coplay go through the Unity platform, understand developer workflows,
and adjust settings on it's own is really exciting and demonstrates how ripe the game
industry is for AI discruption. But you can already see a world where Coplay lives
as a full abstraction layer on top of any game engine. In this world, Coplay is the
main interface with the engine living underneath it. Users interact with Coplay
similar to how Roblox has done it with a simplified workflow on top of their own game engine.
In this version, however, the game engine becomes secondary to the translation
layer (in this case Coplay) and game development as a feature can become as
easy as embedding a chat interface with an iframe representing the Scene / Game View.

<br />
This may sound kinda far-fetched but there are two analogues that come to mind here
– the first is the relationship between AI features today and the underlying models
they rely on. For people who are interested, the models matter but for the most part,
the average person (even one using AI tooling) does not know which models they are
using and in what combination. When trying to get through customer service, ask Siri
a question, or edit a document, they just care about results. The best companies
creating workflows for AI development (make.com, n8n) are really good at abstracting
away implementation details so the user can focus on results.
<br />
The second analogue is React Native, a write-once in TS/JS and deploy everywhere
framework. React Native is not so abstracted as to be a drag and drop interface;
in fact, it is relatively complex in the types of apps and structures you want to
create with it. However, there will will occasionally be a point where a package
you want to install won’t work nicely with React Native and you need to eject your
app into native code (e.g. Java / Obj-C). This is a one-way ejection so there’s no
going back but then you have a full project of native code set up with a lot of boilerplate
already done. The game engine itself is a set of abstractions collected into a single
environment but that's not to say that it’s the final form of game development. Unity
/ Unreal may be the right tool for the job eventually but starting a new project
in them may not be.
<br />
### Remaining Thoughts
<br />
#### Intelligent Context Management

Perhaps Coplay's most significant technical challenge involves context handling. Modern games comprise thousands
or even tens of thousands of unique files—a labyrinth of assets, scripts, and configurations
that could potentially be prohibitively expensive (either in pure $$$ or just time / efficiency)
to tokenize and process in their entirety. This context handling capability likely represents
Coplay's core innovation and competitive advantage. The true breakthrough isn't merely getting
an AI to perform impressive tasks; it's enabling it to do so efficiently and economically
within the sprawling ecosystem of a game project.

<br />
*Advanced techniques might include:*
<br />
_-Persistent context on high-level project architecture_

_-Graph-based representation of project components that maps relationships_

_-Dynamic context windowing that focuses on relevant files and relationships_

_-Specialized agents trained for relevant context retrieval_

<br />
#### Autonomous Agents Governance

Coplay comes with variable settings for the extent to which the AI should make changes to your project (e.g.
Normal vs. Beast mode where the AI will take on much more responsibility and independent judgements.)
The question becomes that if you have a team of agents working on a project, perhaps completely
independently, how do you ensure changes made by these agents are in line with the vision of the project?
For that, I think there are three necessary features (which, by the way, they may already be working on, not sure):

<br />
**1. Version Control** - This is a must-have for any project but especially for one
where multiple agents are making changes. There already is [Unity Version Control](https://unity.com/solutions/version-control)
but imagine being able to see the agent's [chain-of-thought](https://arxiv.org/abs/2201.11903),
identify where an agent went off-course, roll back to that previous state and start
a new iteration. Or branch it from a certain point and test an alternate version.
With this version control for generative AI, agents can create as many permutations
of a project as desired and the developer can choose the one that best fits their
vision.
<br />

**2. Role Based Permissions** - Like any external developer that you would grant system access to,
there need to be guardrails of what resources the AI can access and what it can do with them.
The Normal vs. Beast mode is the beginning of this and helps match developer velocity with risk
tolerance. But that assumes that there is a [Human in the loop](https://en.wikipedia.org/wiki/Human-in-the-loop),
which is a massive help in ensuring each change is in line with the project vision. In a fully agentic system,
being able to to give specific permissions and motivations to agents helps simulate a real-world team environment.
You can easily imagine a system where one agent responsible for asset creation is given more leeway to
experiment with new styles and techniques while another agent responsible for combat mechanics is
given more strict guidelines to follow.

<br />

**3. Contextual Audit Logs** - Seeing that a setting was modified is one thing but understanding
the context of why it was changed, what logic went into making that change, and what else was changed
alongside it is essential for ensuring the project doesn't become a black box that no one can understand.
I believe this was mentioned in the talk but I think it's worth reiterating that this is a critical
feature for any AI-assisted development tool. A comprehensive audit system would capture:

<br />

_-The contextual information available to agents when making decisions_

_-The reasoning process leading to specific implementation choices_

_-Relationships between seemingly unrelated changes_

_-Potential alternative approaches considered but not implemented_

<br />

A well-designed knowledge graph of all decisions, modifications,
and outcomes ensures that human developers still have full oversight into the project and can trace back
any changes to their source.

<br />

---

<br />

I was listening to a talk on Youtube recently (can't remember who it was unfortunately) and there was a
really interesting. I'm paraphrasing but essentially the sentiment was:

<br />

##### "We want robots to do our laundry and dishes so that we can have more time to create art. We don't want robots to create art so we have more time for laundry and dishes."

<br />
The most promising aspect of Coplay's approach is that it doesn't attempt to replace
human creativity but rather amplifies it by removing barriers between conception
and implementation. In doing so, it might help fulfill the original promise of game
engines themselves: making game development more accessible without sacrificing depth
or possibility.
